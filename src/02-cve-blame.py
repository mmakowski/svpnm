#!/usr/bin/env python
"""
Construct a data structure that maps CVEs to lines that are "blamed" for the vulnerability,
and to commits that introduced those lines.
"""

import collections
import configparser
import difflib
import gzip
import json
import logging
import multiprocessing as mp
import os
import re
import sys

import git

import project


# logging
logging.basicConfig(format='%(asctime)s %(process)s %(levelname)-8s %(message)s', stream=sys.stdout)
log = logging.getLogger()
log.setLevel(logging.INFO)

INPUT_DIR = 'data/raw/nvdcve/json'
FIX_COMMIT_PATTERN = re.compile(r".*?(github\.com|git\.kernel\.org).*?torvalds.*?(commit)+.*?(h=|/)+([a-z0-9]+)")
FIX_COMMIT_GROUP = 4
DESC_FILE_PATTERN = re.compile(r"\b[0-9A-Za-z_/]+\.c\b")
DESC_FILE_GROUP = 0
DESC_FUNCTION_PATTERN = re.compile(r"\b([0-9A-Za-z_]+)\s+(function|implementation)\s+in")
DESC_FUNCTION_GROUP = 1
MAX_FIX_COMMITS = 4

# configuration
config = configparser.ConfigParser()
config.read('config.ini')
PARALLELISM = int(config['environment']['parallelism'])


def main():
    cves = _parse_cves()
    cves = _remove_cves_with_unerasonable_number_of_commits(cves)
    repo = git.Repo(project.REPO_DIR)
    _append_commit_details(cves, repo)
    log.info("writing %s", project.CVE_BLAME_FILE)
    with open(project.CVE_BLAME_FILE, 'w') as of:
        json.dump(cves, of)


def _parse_cves():
    cves = dict()
    for input_file in sorted(os.listdir(INPUT_DIR)):
        log.info("parsing %s", input_file)
        with gzip.open(os.path.join(INPUT_DIR, input_file), 'rt') as f:
            content = json.load(f)
            _append_cves(content['CVE_Items'], cves)
            log.info("%d CVEs collected so far", len(cves))
    return cves


def _remove_cves_with_unerasonable_number_of_commits(cves):
    len_before_removal = len(cves)
    updated_cves = {
        cve_id: cve_data
        for cve_id, cve_data in cves.items()
        if len(cve_data['fix_commits']) <= MAX_FIX_COMMITS
    }
    len_after_removal = len(updated_cves)
    log.info("rejected %d CVEs with more than %d fix commits",
             len_before_removal - len_after_removal,
             MAX_FIX_COMMITS)
    return updated_cves


def _append_commit_details(cves, repo):
    log.info("resolving commit details...")
    with mp.Pool(PARALLELISM) as pool:
        commit_details = dict(pool.map(_commit_details_for_cve,
                                       zip([repo] * len(cves), cves.items())))
    for cve_id in cves:
        cves[cve_id]['fix_commits'] = commit_details[cve_id]


def _commit_details_for_cve(args):
    repo, (cve_id, cve_data) = args
    log.info("resolving %s with commits %s", cve_id, str(cve_data['fix_commits']))
    return (cve_id, {
        commit_hash: _commit_details(repo.commit(commit_hash))
        for commit_hash in cve_data['fix_commits']
        if _is_valid_commit(commit_hash, repo)
    })


def _is_valid_commit(commit_hash, repo):
    try:
        repo.commit(commit_hash)
        return True
    except:
        log.warn("missing commit %s, skipping", commit_hash)
        return False


def _commit_details(commit):
    return {
        'committed_timestamp': commit.committed_datetime.isoformat(),
        'affected_files': _files_affected_by_commit(commit)
    }


def _files_affected_by_commit(commit):
    return {
        file_path: blame_details
        # ASSUMPTION: the first parent commit is the "closest" ancestor, and diff to that commit is the only relevant diff
        for diff in commit.parents[0].diff(commit)
        if diff.change_type != 'A'
        for file_path, blame_details in [_blame_details_from_diff(diff, commit.parents[0])]
    }


def _blame_details_from_diff(diff, parent_commit):
    if diff.change_type in ['M', 'D', 'R']:
        return (
            diff.a_path,
            {'blame_lines': _blame_details(diff, parent_commit)}
        )
    else:
        raise ValueError("unexpected change type: %s" % diff.change_type)


def _blame_details(diff, parent_commit):
    blame_lines = _blame_lines(diff)
    blame_commits = _blame_commits_for_lines(parent_commit, diff.a_path, blame_lines)
    return blame_commits


def _blame_lines(diff):
    def lines(blob, path):
        try:
            return blob.data_stream.read().decode('utf-8').split("\n")
        except UnicodeDecodeError:
            log.exception("unable to decode %s as UTF-8 text", path)
            return []
    a_lines = lines(diff.a_blob, diff.a_path)
    if diff.change_type == 'D':
        # blame all lines of the deleted file
        return list(range(1, len(a_lines)+1))
    b_lines = lines(diff.b_blob, diff.b_path)
    log.debug("diffing %s", diff.a_path)
    operations = difflib.SequenceMatcher(a=a_lines, b=b_lines).get_opcodes()

    def blame_lines(opcode, a_start, a_end):
        if opcode == 'equal':
            return []
        elif opcode == 'insert':
            # blame lines before and after the inserted block
            return [a_start-1, a_end]
        else:
            # blame all deleted or replaced lines
            return list(range(a_start, a_end))

    result = set([ 
        line
        for opcode, a_start, a_end, b_start, b_end in operations
        # note that line number must be adjusted by +1, since line count in a file is 1-based and
        # the list of lines indexing is 0-based
        for lines in [blame_lines(opcode, a_start+1, a_end+1)]
        for line in lines
    ])
    log.debug("%d lines blamed", len(result))
    return result


def _blame_commits_for_lines(commit, path, lines):
    return sorted([
        {'line_no': line, 'blame_commit': blame_entry.commit.hexsha}
        for blame_entry in commit.repo.blame_incremental(commit, path)
        for line in blame_entry.linenos
        if line in lines
    ], key=lambda d: d['line_no'])


def _append_cves(cve_list, output_cves):
    output_cves.update({
        cve['cve']['CVE_data_meta']['ID']: {
            'fix_commits': commits,
            'cve_desc_files': files,
            'cve_desc_functions': functions
        }
        for cve in cve_list
        for commits in [_cve_fix_commits(cve)]
        if len(commits) > 0
        for files in [_cve_desc_files(cve)]
        for functions in [_cve_desc_functions(cve)]
    })


def _cve_fix_commits(cve):
    return set([
        match.group(FIX_COMMIT_GROUP)
        for reference in cve['cve']['references']['reference_data']
        for match in [FIX_COMMIT_PATTERN.match(reference['url'])]
        if match and reference['refsource'] == 'CONFIRM'
    ])


def _cve_desc_files(cve):
    return _cve_desc_matches(cve, DESC_FILE_PATTERN, DESC_FILE_GROUP)


def _cve_desc_functions(cve):
    return _cve_desc_matches(cve, DESC_FUNCTION_PATTERN, DESC_FUNCTION_GROUP)


def _cve_desc_matches(cve, pattern, group):
    return [
        match.group(group)
        for datum in cve['cve']['description']['description_data']
        for match in pattern.finditer(datum['value'])
    ]


if __name__ == '__main__':
    main()
